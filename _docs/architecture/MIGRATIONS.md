# CDC Migration System

> Auto-generated PostgreSQL DDL from service-schema YAML definitions, with schema evolution detection, version tracking, and operational tooling.

---

## Overview

The migration system bridges the gap between MSSQL source schemas (inspected and stored as YAML) and the PostgreSQL sink database. It generates, tracks, and applies DDL migrations through a deterministic pipeline:

```text
MSSQL source tables
      │  (cdc manage-services resources --inspect)
      ▼
services/_schemas/{service}/{schema}/{table}.yaml    ← 170 YAML definitions
      │  (cdc manage-migrations generate)
      ▼
migrations/{sink_name}/                              ← generated SQL files + manifest
      │  (cdc manage-migrations diff / apply / status)
      ▼
PostgreSQL target database
```

Every step is driven by the CLI (`cdc manage-migrations <subcommand>`) and lives entirely in the generator library — implementations contain only YAML configuration and generated artifacts.

---

## Architecture

### Input: Service-Schema YAML

Table definitions are stored as YAML files under `services/_schemas/{service}/{schema}/`:

```yaml
# services/_schemas/{service}/{schema}/{table}.yaml
database: SOURCE_DB
schema: dbo
service: my_service
table: Actor
columns:
  - name: actno
    type: int            # MSSQL type — mapped to PG at generation time
    nullable: false
    primary_key: true
  - name: Navn
    type: varchar
    nullable: true
```

These files are created/updated by `cdc manage-services resources --inspect` which connects to MSSQL and introspects the live schema.

### Output: Generated Migrations

Migrations are organised per **sink target** (from `services/{service}.yaml`):

```text
migrations/
└── sink_target_name/
    ├── manifest.yaml                          # Metadata + file index
    ├── 00-infrastructure/
    │   ├── 01-create-schemas.sql              # CREATE SCHEMA statements
    │   └── 02-cdc-management.sql              # Merge control, monitoring, history
    └── 01-tables/
        ├── Actor.sql                          # CREATE TABLE (final table)
        ├── Actor-staging.sql                  # CREATE TABLE (staging + trigger + merge proc)
        ├── ActorActor.sql
        ├── ActorActor-staging.sql
        └── ...                                # N tables × 2 files each
```

### Column Pipeline

Each table's column list is built through a deterministic pipeline:

```text
Schema YAML columns
      │
      ├─ 1. build_columns_from_table_def()     → Parse YAML + MSSQL→PG type mapping
      ├─ 2. _add_column_template_columns()      → Add pattern columns (_customer_id, etc.)
      └─ 3. _add_cdc_metadata_columns()         → Add __sync_timestamp, __source, etc.
```

This ensures every generated DDL file has the exact same column set. The diff engine (`build_full_column_list()`) reuses this pipeline for accurate comparison.

### Type Mapping

MSSQL types are converted to PostgreSQL using bidirectional mapping files:

```text
service-schemas/adapters/mssql-to-pgsql.mapping.yaml
```

| MSSQL Type | PostgreSQL Type |
|---|---|
| `int` | `integer` |
| `varchar` / `nvarchar` | `varchar` |
| `datetime` / `datetime2` | `timestamp` |
| `uniqueidentifier` | `uuid` |
| `bit` | `boolean` |
| `float` | `double precision` |
| `image` / `varbinary` | `bytea` |
| *(unknown)* | `text` (fallback) |

---

## Version Management

### SHA256 Checksums

Every generated SQL file includes a checksum in its header:

```sql
-- ============================================================================
-- DO NOT EDIT — AUTO-GENERATED by: cdc manage-migrations generate
-- Generated: 2026-02-26 22:00:31 UTC
-- Source: MSSQL [dbo].[Actor]
-- Target: "target_schema"."Actor"
-- ============================================================================
-- Checksum: sha256:bef78cac58d9263d50999742f4fa6fab6a3ee386d9ecd966294b3b31ebb007e6
CREATE TABLE IF NOT EXISTS "target_schema"."Actor" (
    ...
```

**How it works:**

1. **Generation:** SQL content is rendered without the checksum line. A SHA256 hash is computed over that content, then the `-- Checksum: sha256:...` line is injected after the header block.
2. **Verification:** When applying, the checksum line is stripped before hashing; the computed hash must match the embedded one.
3. **Tamper detection:** If a file was manually edited, the checksum won't match — the apply engine flags it.

### Migration History Table

Applied migrations are tracked in `cdc_management.migration_history`:

```sql
CREATE TABLE IF NOT EXISTS "cdc_management"."migration_history" (
    "id"           BIGSERIAL    PRIMARY KEY,
    "file_name"    TEXT         NOT NULL,
    "checksum"     TEXT         NOT NULL,
    "schema_name"  TEXT,
    "category"     TEXT         NOT NULL,     -- 'infrastructure', 'table', 'staging'
    "applied_at"   TIMESTAMPTZ  NOT NULL DEFAULT NOW(),
    UNIQUE ("file_name", "schema_name")
);
```

**Idempotent re-runs:** If a file was already applied with the same checksum, it's skipped. If the checksum changed (regeneration after schema evolution), it's re-applied and the history record is updated via `ON CONFLICT DO UPDATE`.

### Manifest

Each sink target gets a `manifest.yaml` recording:

```yaml
generated_at: "2026-02-26 22:00:31 UTC"
table_count: <generated>
schema_count: <generated>
sink_target:
  name: "sink_target_name"
  databases:
    dev: "directory_dev"
    prod: "directory"
    stage: "directory_stage"
infrastructure:
  - 00-infrastructure/01-create-schemas.sql
  - 00-infrastructure/02-cdc-management.sql
tables:
  - 01-tables/Actor.sql
  - 01-tables/Actor-staging.sql
  # ...
```

The manifest is used by the apply engine to resolve the correct database name per environment.

---

## Schema Evolution Detection

The diff engine parses existing generated SQL files and compares them against the current service-schema YAML definitions:

```bash
cdc manage-migrations diff [--service <name>] [--table Actor]
```

**What it detects:**

| Change Kind | Severity | Example |
|---|---|---|
| `TABLE_ADDED` | info | New table in service config, no SQL file |
| `TABLE_REMOVED` | warning | SQL file exists, table removed from config |
| `COLUMN_ADDED` | info | New column in YAML, not in DDL |
| `COLUMN_REMOVED` | warning | Column in DDL, not in YAML |
| `COLUMN_TYPE_CHANGED` | breaking | Type mismatch between YAML and DDL |
| `PRIMARY_KEY_CHANGED` | breaking | PK definition differs |

**How it works:**

1. Load service-schema YAML and build expected columns using `build_full_column_list()` — the same pipeline the generator uses (including column templates and CDC metadata).
2. Parse the existing `CREATE TABLE` DDL from generated SQL files using regex extraction.
3. Compare column-by-column, detecting additions, removals, and type changes.
4. Produce a `DiffResult` with severity-tagged `SchemaChange` entries.

**Regex handles:**

- Single-word types: `varchar`, `integer`, `boolean`, `timestamp`
- Multi-word types: `double precision`, `character varying`
- Type parameters: `VARCHAR(255)`, `NUMERIC(10,2)`

**Exit codes:** 0 = no changes, 1 = changes detected, 2 = error.

---

## Infrastructure: Merge Control & Monitoring

The `02-cdc-management.sql` infrastructure file creates a complete event-driven merge system:

| Component | Purpose |
|---|---|
| `merge_control` | Tracks which tables have pending staging data |
| `mark_table_for_merge()` | Trigger function called by staging table INSERT triggers |
| `trigger_pending_merges()` | Orchestrator called by pg_cron; finds pending tables and calls `sp_merge_{table}()` |
| `cdc_processing_log` | Offset tracking, gap detection, replication lag monitoring |
| `migration_history` | Tracks applied migration files + checksums |
| `error_log` | Merge failure details with timestamps |
| `v_merge_status` | View: current merge state per table |
| `v_recent_errors` | View: last 100 errors |
| `v_cdc_processing_gaps` | View: Kafka offset gaps between batches |
| `v_cdc_replication_lag` | View: time lag between source and sink |
| `manual_merge()` | Utility function for ad-hoc merges |

### Staging Table Pattern

For each table, two SQL files are generated:

1. **`{Table}.sql`** — The final/target table with all columns, PK, and sync timestamp index.
2. **`{Table}-staging.sql`** — The staging (UNLOGGED) table, INSERT trigger, and `sp_merge_{table}()` stored procedure that performs UPSERT from staging → final.

This enables the event-driven merge pattern where Kafka sink connectors write to staging tables and pg_cron orchestrates batch merges.

---

## CLI Reference

All commands live under `cdc manage-migrations`:

### `generate`

Generate PostgreSQL migration SQL files from service config + table definitions.

```bash
cdc manage-migrations generate                      # Generate all
cdc manage-migrations generate --table Actor        # Single table
cdc manage-migrations generate --dry-run            # Preview only
```

### `diff`

Compare service-schema definitions against generated migrations to detect schema evolution.

```bash
cdc manage-migrations diff                          # Full diff
cdc manage-migrations diff --table Actor            # Single table
```

### `apply`

Apply pending migrations to target PostgreSQL database.

```bash
cdc manage-migrations apply --env dev               # Apply to dev
cdc manage-migrations apply --env stage --dry-run   # Preview what would run
cdc manage-migrations apply --env prod --sink <sink_name>
```

**Execution order:** Infrastructure files first (sorted by number), then table DDL files, then staging files. This ensures schemas and management tables exist before table DDL, and final tables exist before staging triggers reference them.

**Connection:** Uses `PG_{ENV}_HOST`, `PG_{ENV}_PORT`, `PG_{ENV}_USER`, `PG_{ENV}_PASSWORD` environment variables. Database name comes from the manifest's `sink_target.databases.{env}` entry.

### `status`

Show applied vs pending migration status.

```bash
cdc manage-migrations status --env dev              # Compare with DB
cdc manage-migrations status --offline              # List files only (no DB)
```

**Online mode:** Connects to PG, queries `migration_history`, compares checksums. Shows applied/pending/modified per file.

**Offline mode:** Lists all migration files as pending without connecting.

### `enable-cdc`

Enable CDC tracking on MSSQL source tables.

```bash
cdc manage-migrations enable-cdc --env nonprod              # All tables
cdc manage-migrations enable-cdc --env nonprod --table Actor
cdc manage-migrations enable-cdc --env nonprod --dry-run
```

Calls `sys.sp_cdc_enable_table` on each source table. Skips tables already tracked (`is_tracked_by_cdc`).

### `clean-cdc`

Clean old CDC change tracking data from MSSQL.

```bash
cdc manage-migrations clean-cdc --env nonprod               # Default: 30 days
cdc manage-migrations clean-cdc --env nonprod --days 60
cdc manage-migrations clean-cdc --env nonprod --dry-run
```

Calls `sys.sp_cdc_cleanup_change_table` to remove entries older than N days.

---

## Pattern Support

| Pattern | Behavior |
|---|---|
| `db-per-tenant` | Each customer gets its own MSSQL database. Column templates may add `_customer_id` (UUID) for cross-tenant queries in the shared PG sink. |
| `db-shared` | Single MSSQL database with `customer_id` in every table. Validation warns if any table is missing a `customer_id` column template. |

The generator validates pattern-specific rules and adds appropriate column templates automatically.

---

## Techniques & Design Decisions

| Technique | Rationale |
|---|---|
| **YAML → SQL generation (not hand-written DDL)** | Single source of truth in service-schema YAML; DDL is always reproducible |
| **SHA256 checksums** | Detect manual edits; enable safe idempotent re-application |
| **Full column pipeline in diff** | Using `build_full_column_list()` ensures diff sees exactly what the generator produces — no false positives from missing column templates or CDC metadata |
| **Per-sink organisation** | Each sink target gets its own directory + manifest, supporting multiple PG databases from one service |
| **UNLOGGED staging tables** | Write-ahead log not needed for transient staging data; significantly faster inserts from Kafka |
| **Event-driven merge** | Triggers + pg_cron batch window avoids per-row merge overhead; handles bursty CDC streams |
| **Deterministic file ordering** | `00-infrastructure/` before `01-tables/`; DDL before staging; ensures dependency order |
| **MSSQL→PG type mapping** | Bidirectional YAML mapping files; extensible; fallback to `text` for unknown types |
| **Migration history with ON CONFLICT** | Safe re-runs: skip unchanged files, update changed ones, never duplicate |
| **`DiffContext` dataclass** | Bundles shared parameters to stay within the 7-argument function limit |

---

## Module Map

### Core Modules (generator library)

| Module | Lines | Purpose |
|---|---|---|
| `core/migration_generator.py` | ~1295 | SQL generation engine, column pipeline, checksum injection |
| `core/migration_diff.py` | ~596 | Schema evolution diff, DDL parsing, column comparison |
| `core/migration_apply.py` | ~488 | Apply engine, PG connection, history tracking |
| `core/migration_status.py` | ~331 | Status reporter (online + offline modes) |
| `core/migration_ops.py` | ~330 | MSSQL CDC operations (enable/clean) |

### CLI Wrappers

| Module | Subcommand |
|---|---|
| `cli/migration_generate.py` | `cdc manage-migrations generate` |
| `cli/migration_diff.py` | `cdc manage-migrations diff` |
| `cli/migration_apply.py` | `cdc manage-migrations apply` |
| `cli/migration_status.py` | `cdc manage-migrations status` |
| `cli/migration_enable_cdc.py` | `cdc manage-migrations enable-cdc` |
| `cli/migration_clean_cdc.py` | `cdc manage-migrations clean-cdc` |

### Templates

Jinja2 templates in `cdc_generator/templates/migrations/` render the SQL DDL. Column definitions are built in Python (not Jinja2) for precise control over formatting and type mapping.

---

## Implementation-specific Metrics

This architecture document intentionally stays implementation-agnostic.

- Keep service-specific migration stats (file counts, schema names, sink names, test counts) in each implementation repository.
- For AdOpus, maintain these metrics in the implementation docs under `docs-adopus-specific/`.
